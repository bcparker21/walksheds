{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import partridge as ptg\n",
    "import datetime\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "from shapely.geometry import mapping, shape\n",
    "from shapely.ops import cascaded_union\n",
    "from fiona import collection\n",
    "from IPython.display import clear_output\n",
    "import threading\n",
    "import multiprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"/Users/brianparker/Work/VRT_Transit1.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_ids_by_date=ptg.read_service_ids_by_date(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=datetime.date(2018, 6, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_ids=service_ids_by_date[date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed=ptg.load_feed(path,view={\n",
    "    'trips.txt':{\n",
    "        'service_id':service_ids,\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=feed.stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Coordinates']=list(zip(df.stop_lat,df.stop_lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfolder=r\"/Users/brianparker/Work/Walksheds/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwalksheds=[]\n",
    "allwalksheds=gpd.GeoDataFrame(allwalksheds)\n",
    "d={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader2(df):\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            clear_output(wait=True)\n",
    "            stopname=row['stop_name']+\"_\"+row['stop_id']\n",
    "            d['{}'.format(stopname)]=ox.graph_to_gdfs((ox.graph_from_point(row['Coordinates'],distance=800,network_type='walk',clean_periphery=False)),node_geometry=False,nodes=False)\n",
    "            print('reading  {} ({} of {})'.format(row['stop_name'],index,len(df)))\n",
    "        except Exception:\n",
    "            print(stopname+\" ERROR ERROR ERROR ERROR ERROR\")\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reader():\n",
    "#     for i in os.listdir(outfolder):\n",
    "#         d['{}'.format(i)]=gpd.read_file(outfolder+\"\\\\\"+i+\"\\\\edges\\\\edges.shp\")\n",
    "#         print('reading: '+i)\n",
    "#     for key,value in d.items():\n",
    "#         allwalksheds.append(value[:])\n",
    "#         print('appending: '+ key)\n",
    "#         return allwalksheds\n",
    "#     allwalksheds.plot()\n",
    "#     allwalksheds.to_file(r\"N:\\Planning - New File Structure\\GIS\\Data\\Stops\\allwalkshedsQtr.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloadThreads = []             # a list of all the Thread objects\n",
    "# for i in range(0, 1400, 100):    # loops 14 times, creates 14 threads\n",
    "#     downloadThread = threading.Thread(target=reader2)\n",
    "#     downloadThreads.append(downloadThread)\n",
    "#     downloadThread.start()\n",
    "# for downloadThread in downloadThreads:\n",
    "#     downloadThread.join()\n",
    "# print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading  Overland & Owyhee (231 of 791)\n"
     ]
    }
   ],
   "source": [
    "reader2(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in d.items():\n",
    "    allwalksheds=allwalksheds.append(value[:])\n",
    "    print('appending: '+ key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwalksheds.plot(figsize=(20,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create as many processes as there are CPUs on your machine\n",
    "# num_processes = multiprocessing.cpu_count()\n",
    "\n",
    "# # calculate the chunk size as an integer\n",
    "# chunk_size = int(df.shape[0]/num_processes)\n",
    "\n",
    "# # this solution was reworked from the above link.\n",
    "# # will work even if the length of the dataframe is not evenly divisible by num_processes\n",
    "# chunks = [df.ix[df.index[i:i + chunk_size]] for i in range(0, df.shape[0], chunk_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pool=multiprocessing.Pool(processes=num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result=pool.map(reader2,chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key,value in d.items():\n",
    "#     clear_output(wait=True)\n",
    "#     allwalksheds=allwalksheds.append(value[:])\n",
    "#     print(key)\n",
    "#     allwalksheds.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processes=[multiprocessing.Process(target=reader2(df))for x in range(8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in processes:\n",
    "#     p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in processes:\n",
    "#     p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allwalksheds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
